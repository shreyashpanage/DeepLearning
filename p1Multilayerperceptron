import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load the Iris dataset
data = load_iris()
X = data.data  # Features: sepal length, sepal width, petal length, petal width
y = data.target  # Target: Species (setosa, versicolor, virginica)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Standardize the features (important for MLP performance)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the MLP model
mlp = MLPClassifier(
    hidden_layer_sizes=(10, 10),  # Two hidden layers with 10 neurons each
    activation='relu',           # ReLU activation function
    solver='adam',               # Adam optimizer
    max_iter=500,                # Maximum number of iterations
    random_state=42              # Random seed for reproducibility
)

# Train the MLP model
mlp.fit(X_train, y_train)

# Make predictions
y_pred = mlp.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=data.target_names))

# Example of making a single prediction
sample = [[5.1, 3.5, 1.4, 0.2]]  # Example input: Sepal length, Sepal width, Petal length, Petal width
sample_scaled = scaler.transform(sample)
prediction = mlp.predict(sample_scaled)
print("\nPredicted species for the sample:", data.target_names[prediction[0]])
